---
title:  "확률론 기초(Stats 110) : Lesson 17. Moment Generating Function"
excerpt: "하버드 대학교 조셉 K. 블리츠타인 교수의 Stats 110 17강 정리"

categories:
  - 통계학
  - 확률론
tags:
  - 무기억성
  - 적률생성함수
use_math: true
comments: true
last_modified_at: 2021-03-09T23:30:00
header:
  image: /assets/images/texture.jpg
---

<img src="/assets/images/stats_110/lesson_17.jpg" width="70%" height="60%" title="button" alt="button"/> 

# 1. 지수분포

- [**무기억성**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_17/#%EB%AC%B4%EA%B8%B0%EC%96%B5%EC%84%B1)


## 무기억성

**지수분포**는 무기억성을 지닌 유일한 연속확률분포이다. 따라서 확률변수 $X$가 무기억성을 지닌다면 $X \sim Expo(\lambda)$가 성립한다. 무기억성의 수학적 정의는 다음과 같다.

\begin{align}
P(X \geq s+t \mid X \geq s) = P(X \geq t) \nonumber
\end{align}

\begin{align}
P(X \geq s+t , X \geq s) = P(X \geq s) \cdot P(X \geq t) \nonumber
\end{align}

$X$에 대한 함수 $G$를 $G(x) = P(X > x) = 1 - F(x)$로 정의하면 무기억성은 $G(s+t) = G(s) \cdot G(t)$로도 표현할 수 있다. 이 때 함수 $G$는 다음과 같은 성질을 갖는다.

\begin{align}
s=t, \quad G(2t) = G(t+t) = G(t) \cdot G(t) = \Big\[G(t)\Big\]^{2}
\nonumber
\end{align}

\begin{align}
s=2t, \quad G(3t) = G(2t+t) = G(2t) \cdot G(t) = \Big\[G(t)\Big\]^{3}
\nonumber
\end{align}

\begin{align}
\therefore s = kt, \quad G(kt) = \Big\[G(t)\Big\]^{k}
\nonumber
\end{align}

즉, $k$가 정수라면 $G(kt)$의 값은 $G(t)$의 $k$ 제곱과 같다. 함수 $G$는 다음과 같은 성질도 가지고 있다.

\begin{align}
s=\frac{1}{2}t, \quad G(2t) = \Big\[G(t)\Big\]^{2} \rightarrow G(t) = \Big\[G(\frac{t}{2})\Big\]^{2}
\nonumber
\end{align}

\begin{align}
\therefore \Big\[G(t)\Big\]^\frac{1}{2} = G(\frac{t}{2})
\nonumber
\end{align}

\begin{align}
s=\frac{1}{3}t, \quad G(3t) = \Big\[G(t)\Big\]^{3} \rightarrow G(t) = \Big\[G(\frac{t}{3})\Big\]^{3}
\nonumber
\end{align}

\begin{align}
\therefore \Big\[G(t)\Big\]^\frac{1}{3} = G(\frac{t}{3})
\nonumber
\end{align}

\begin{align}
\therefore s = \frac{1}{k}t, \quad G(\frac{t}{k}) = \Big\[G(t)\Big\]^\frac{1}{k}
\nonumber
\end{align}

즉, $k$가 정수라면 $G(\frac{t}{k})$의 값은 $G(t)$의 $\frac{1}{k}$ 제곱과 같다. 위에서 확인한 두 성질에 의해 다음이 성립한다.

\begin{align}
s = m \times \frac{t}{n}, \quad G(m \times \frac{t}{n}) = \Big\[G(\frac{t}{n})\Big\]^{m} \nonumber
\end{align}

\begin{align}
\Big\[G(\frac{t}{n})\Big\]^{m} = \Big\[G(t)^\frac{1}{n}\Big\]^m = \Big\[G(t)\Big\]^\frac{m}{n}
\nonumber
\end{align}

\begin{align}
\therefore s = \frac{mt}{n}, \quad G(\frac{mt}{n}) = \Big\[G(t)\Big\]^\frac{m}{n}
\nonumber
\end{align}

따라서 모든 유리수 $\frac{m}{n}$에 대하여 위 성질이 성립함을 확인할 수 있다. 함수 $G$가 연속함수이므로 $G(\frac{mt}{n}) = \Big\[G(t)\Big\]^\frac{m}{n}$에서, 양변에 **극한**을 씌우고 극한과 함수 $G$의 순서를 바꿀 수 있다. 그렇게 되면 모든 실수는 유리수열의 극한이므로 $x > 0$인 모든 실수에 대하여 $G(xt) = \Big\[G(t)\Big\]^{x}$가 성립한다.

이제 $t=1$로 놓으면 $G(1) = G(x) = e^{x \ln(G(1))}$이 성립한다. $G(1)$은 어떤 확률이므로 $0$과 $1$사이의 실수이며 여기에 로그를 취함으로써 $\ln(G(1))$의 값은 음수가 되는데 이를 $-\lambda \;\; (\lambda > 0)$으로 치환한다.

치환을 하게 되면 $G(x) = e^{-\lambda x}$이다. $F(x) = 1-G(x)$이므로 $F(x) = 1-e^{-\lambda x}$이다. 이는 지수분포를 따르는 확률변수의 CDF와 같다.

따라서 어떤 확률변수가 무기억성을 지닌다면 그 확률변수는 반드시 지수분포를 따른다는 결론을 얻을 수 있다.

* * * 
<br>

# 2. 적률생성함수

- [**적률생성함수의 정의**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_17/#%EC%A0%81%EB%A5%A0%EC%83%9D%EC%84%B1%ED%95%A8%EC%88%98%EC%9D%98-%EC%A0%95%EC%9D%98)
- [**이항분포**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_17/#%EC%9D%B4%ED%95%AD%EB%B6%84%ED%8F%AC)
- [**지수분포**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_17/#%EC%A7%80%EC%88%98%EB%B6%84%ED%8F%AC)
- [**표준정규분포**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_17/#%ED%91%9C%EC%A4%80%EC%A0%95%EA%B7%9C%EB%B6%84%ED%8F%AC)
- [**포아송분포**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_17/#%ED%8F%AC%EC%95%84%EC%86%A1%EB%B6%84%ED%8F%AC)


## 적률생성함수의 정의

확률변수 $X$의 적률생성함수(**MGF**; Moment Generating Function)는 $t$에 관한 함수인 $M(t) = E(e^{tX})$로 정의된다.

만약 $0$을 포함하는 구간 $\[-a, a\], \;\; a>0$에서 MGF의 값이 유한하다면 MGF가 유의미하게 사용될 수 있다. $M(t)$를 **테일러 급수**에 의해 다음과 같이 쓸 수 있다.

\begin{align}
M(t) = E(e^{tX}) = E\left(\sum_{n=0}^{\infty}\frac{(tX)^{n}}{n!}\right) = \sum_{n=0}^{\infty} \frac{E(X^{n}) \cdot t^{n}}{n!} \nonumber
\end{align}

이 때, $E(X^{n})$을 $n$**차 적률**이라 부른다. 모든 적률이 테일러 급수 안에 존재하기 때문에 $M(t)$를 적률생성함수라고 부르는 것이다.

어떤 확률변수 $X$의 MGF가 존재하면 $n$차 적률 $E(X^{n})$은 $M(t)$를 $n$차 미분한 후 $t$에 $0$을 대입하면 계산이 가능하다. 따라서 $M^{(n)}(0) = E(X^{n})$이다. 위첨자 $(n)$은 $n$번 미분하였음을 나타낸다.

\begin{align}
M(t) = 1 + E(X) \cdot t + E(X^{2}) \cdot \frac{t^{2}}{2!} + E(X^{3}) \cdot \frac{t^{3}}{3!} + \cdots \nonumber
\end{align}

\begin{align}
M^{(1)}(t) = E(X) + E(X^{2}) \cdot t + E(X^{3}) \cdot \frac{t^{2}}{2!} + \cdots \nonumber
\end{align}

\begin{align}
M^{(2)}(t) = E(X^{2}) + E(X^{2}) \cdot t + \cdots \nonumber
\end{align}

\begin{align}
\therefore M^{(1)}(0) = E(X), \quad M^{(2)}(0) = E(X^{2}) \nonumber
\end{align}

MGF가 중요한 이유 두 가지 중 하나는, MGF가 확률분포를 결정하기 때문이다. 만약 두 확률변수 $X$와 $Y$의 MGF가 서로 같다면 $X$와 $Y$는 같은 확률분포를 따른다. 즉, $X$와 $Y$의 PMF/PDF와 CDF가 모두 같다.

또 다른 이유는, MGF를 이용하면 독립적인 확률변수의 합(**합성곱**)의 적률 계산과 확률분포 파악이 쉬워지기 때문이다. $X$의 MGF인 $M\_\{\{\_X\}\}$와 $Y$의 MGF인 $M\_\{\{\_Y\}\}$에 대하여 $X$와 $Y$가 서로 독립이라면 $X+Y$의 MGF에 대해 다음이 성립한다.

\begin{align}
E \left(e^{t(X+Y)} \right) = E \left(e^{tX} \right) \cdot E \left(e^{tY} \right) = M\_\{\{\_X\}\}(t) \cdot M\_\{\{\_Y\}\}(t) \nonumber
\end{align}

$X$와 $Y$가 독립이므로 $e^{tX}$와 $e^{tY}$도 서로 독립이다. 따라서 기댓값을 각각의 곱으로 분리할 수 있다.


## 이항분포

**이항분포**를 따르는 확률변수 $X$에 대하여 $X_{j} \overset{i.i.d} \sim Bern(p)$이면 $X = \sum X_{j}$이므로 $X$의 MGF를 다음과 같이 계산할 수 있다. 우선, $X_{j}$의 MGF를 **LOTUS**를 이용하여 계산한다.
 
\begin{align}
M_{X_{j}}(t) = p \cdot e^{t} + q \nonumber
\end{align}

\begin{align}
\because E(X_{j}) = \sum_{x} x \cdot P(X_{j}=x) \quad \rightarrow \quad E \left(e^{tX_{j}} \right) = \sum_{x} e^{tx} \cdot P(X_{j}=x) \nonumber
\end{align}

이제 이항분포를 따르는 $X$의 MGF를 계산한다.

\begin{align}
M\_{{_X}}(t) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= E\left(e^{tX}\right) \\\\\\ \\\\\\
&= E\left(e^{t(X\_{1}+X\_{2}+ \cdots + X\_{n})} \right) \\\\\\ \\\\\\
&= E \left(e^{tX\_{1}} \right) \times E \left(e^{tX\_{2}} \right) \times \cdots \times E \left(e^{tX\_{n}} \right)\\\\\\ \\\\\\
&= \Big[ E\left(e^{tX\_{1}}\right) \Big ]^{n} \\\\\\ \\\\\\
&= (p \cdot e^{t} + q)^{n} \nonumber
\end{aligned}
\end{equation\*}


## 지수분포

**지수분포**를 따르는 확률변수 $X \sim Expo(1)$의 MGF는 다음과 같은 과정을 통해 계산할 수 있다.

\begin{align}
M(t) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= \int_{0}^{\infty}e^{tx} \cdot e^{-x} \;\; dx \\\\\\ \\\\\\
&= \int_{0}^{\infty} e^{-x(1-t)} \;\; dx \\\\\\ \\\\\\
&= \frac{1}{1-t} \int_{0}^{\infty} (1-t) \cdot e^{-(1-t)x} \;\; dx \\\\\\ \\\\\\
&= \frac{1}{1-t}, \quad t < 1
\end{aligned}
\end{equation\*}

위 식의 가장 마지막에서 $(1-t) \cdot e^{-(1-t)x}$ 부분은 $\lambda = 1-t$인 지수분포의 PDF에 해당하므로 적분값이 1이다. 이제 MGF를 미분한 후 $0$을 대입하여 적률을 계산할 수도 있지만 이 경우에는 **기하급수**를 활용하면 더 간편하게 계산할 수 있다.

\begin{align}
M(t) = \frac{1}{1-t} = \sum_{n=0}^{\infty}t^{n} = \sum_{n=0}^{\infty}n! \cdot \frac{t^{n}}{n!} \;\; , \quad \mid t \mid < 1 \nonumber
\end{align}

\begin{align}
\therefore E(X^{n}) = n! \nonumber
\end{align}

$M(t) = \sum_{n=0}^{\infty} \frac{E(X^{n}) \cdot t^{n}}{n!}$이므로 결국 $E(X^{n}) = n!$가 성립한다.

위 성질을 활용하여 $X \sim Expo(\lambda)$일 때 $X^{n}$의 기댓값을 간단하게 계산할 수 있다. 이 때, $Y = \lambda X$이면 $Y \sim Expo(1)$를 만족한다는 성질을 활용한다.

\begin{align}
X^{n} = \frac{Y^{n}}{\lambda^{n}}\nonumber
\end{align}

\begin{align}
E(X^{n}) = E\left( \frac{Y^{n}}{\lambda^{n}} \right) = \frac{E(Y^{n})}{\lambda^{n}} = \frac{n!}{\lambda^{n}} \nonumber
\end{align}


## 표준정규분포

**표준정규분포**를 따르는 확률변수 $Z \sim N(0, 1)$의 MGF는 다음과 같은 과정을 통해 계산할 수 있다.

\begin{align}
M(t) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= \int_{-\infty}^{\infty}e^{tz} \cdot e^{-\frac{1}{2}z^{2}} \;\; dz \\\\\\ \\\\\\
&= \frac{e^{\frac{1}{2}t^{2}}}{\sqrt{2\pi}} \cdot \int_{-\infty}^{\infty}e^{-\frac{1}{2}(z-t)^{2}} \;\; dz \\\\\\ \\\\\\
&= e^{\frac{1}{2}t^{2}}
\end{aligned}
\end{equation\*}

위 과정에서 $\frac{1}{\sqrt{2\pi}} \cdot e^{-\frac{1}{2}(z-t)^{2}}$는 중심을 $0$에서 $t$로 이동한 표준정규분포의 PDF와 같으므로 적분값이 $1$이 된다.

표준정규분포를 따르는 확률변수의 MGF를 이용하여 다음과 같이 $Z$의 짝수차 적률을 계산할 수 있다.

\begin{align}
M(t) = e^{\frac{1}{2}t^{2}} = \sum_{n=0}^{\infty} \frac{(t^{2}/2)^{n}}{n!} = \sum_{n=0}^{\infty}\frac{t^{2n}}{2^{n} \cdot n!} = \sum_{n=0}^{\infty}\frac{(2n)! \cdot t^{2n}}{2^{n} \cdot n! \cdot (2n)!} \nonumber
\end{align}

\begin{align}
\therefore E(Z^{2n}) = \frac{(2n)!}{2^{n} \cdot n!} \nonumber
\end{align}

\begin{align}
E(Z^{2}) = 1, \quad E(Z^{4}) = 1 \times 3, \quad E(Z^{6}) = 1 \times 3 \times 5, \quad \cdots 
\nonumber
\end{align}


## 포아송분포

**포아송분포**를 따르는 확률변수 $X \sim Pois(\lambda)$의 MGF는 다음과 같은 과정을 통해 계산할 수 있다.

\begin{align}
M(t) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= \sum_{x=0}^{\infty}e^{tx} \cdot \frac{e^{-\lambda} \lambda^{x}}{x!} \\\\\\ \\\\\\
&= e^{-\lambda} \cdot \sum_{x=0}^{\infty} \frac{(e^{t}\lambda)^{x}}{x!} \\\\\\ \\\\\\
&= e^{-\lambda} \cdot e^{e^{t}\lambda} \\\\\\ \\\\\\
&= e^{\lambda(e^{t}-1)} 
\end{aligned}
\end{equation\*}

만약 $X \sim Pois(\lambda)$이고 $Y \sim Pois(\mu)$이고 $X$와 $Y$가 독립이라면 $X+Y$의 MGF는 다음과 같아진다.

\begin{align}
M\_\{\{\_\{X+Y\}\}\}(t) = e^{\lambda(e^{t}-1)} \cdot e^{\mu(e^{t}-1)} = e^{(\lambda+\mu)(e^{t}-1)}\nonumber
\end{align}

\begin{align}
\therefore X+Y \sim Pois(\lambda + \mu) \nonumber
\end{align}

MGF를 통해 포아송분포를 따르고 서로 독립인 확률변수의 합으로 정의된 확률변수 역시 포아송분포를 따른다는 사실을 쉽게 확인할 수 있다.