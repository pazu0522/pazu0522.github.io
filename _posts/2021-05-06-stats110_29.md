---
title:  "확률론 기초(Stats 110) : Lesson 29. Law of Large Numbers and Central Limit Theorem"
excerpt: "하버드 대학교 조셉 K. 블리츠타인 교수의 Stats 110 29강 정리"

categories:
  - 통계학
  - 확률론
tags:
  - 중심극한정리
  - 큰 수의 법칙
use_math: true
comments: true
last_modified_at: 2021-05-06T23:30:00
header:
  image: /assets/images/texture.jpg
---

<img src="/assets/images/stats_110/lesson_29.jpg" width="80%" height="80%" title="number" alt="number"/> 

# 1. 큰 수의 법칙

- [**강한 큰 수의 법칙**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_29/#%EA%B0%95%ED%95%9C-%ED%81%B0-%EC%88%98%EC%9D%98-%EB%B2%95%EC%B9%99)
- [**약한 큰 수의 법칙**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_29/#%EC%95%BD%ED%95%9C-%ED%81%B0-%EC%88%98%EC%9D%98-%EB%B2%95%EC%B9%99)


## 강한 큰 수의 법칙

서로 **독립**이고 **동일한 확률분포**를 따르는 확률변수 $X_{1}, \cdots , X_{n}$에 대하여, $X_{j}$의 **평균**과 **분산**이 각각 $\mu$와 $\sigma^{2}$일 때 $n \rightarrow \infty$이면 $\frac{1}{n} \sum_{j=1}^{n}X_{j} = \bar{X}$가 $\mu$로 수렴할 확률이 $1$이다. 수식으로 표현하면 다음과 같다.

\begin{align}
P \left( \lim_{n \rightarrow \infty} \frac{1}{n} \sum_{j=1}^{n} X_{j} = \mu \right) = 1 \nonumber
\end{align}

즉, **강한 큰 수의 법칙**에 의하면 $n \rightarrow \infty$이면 **표본평균** $\bar{X}$가 **모평균** $\mu$로 수렴한다. 예를 들어, $X_{j} \overset{i.i.d} \sim Bern(p)$이면 $n \rightarrow \infty$에 따라 $\frac{1}{n} \sum_{j=1}^{n}X_{j} \rightarrow p$이다.


## 약한 큰 수의 법칙

임의의 **양의 실수** $c$에 대해 $n \rightarrow \infty$이면 $P(\mid \bar{X}_{n} - \mu \mid > c) \rightarrow 0$가 성립한다. **약한 큰 수의 법칙**은 **체비셰프 부등식**을 통해 간단히 증명 가능하다.

\begin{align}
P(\mid \bar{X}_{n} - \mu \mid > c) \leq \frac{Var(\bar{X}\_{n})}{c^{2}} = \frac{\frac{1}{n^{2}} \cdot n\sigma^{2}}{c^{2}} = \frac{\sigma^{2}}{nc^{2}} \rightarrow 0 \nonumber
\end{align}

\begin{align}
\therefore P(\mid \bar{X}_{n} - \mu \mid > c) \rightarrow 0 \nonumber
\end{align}

$Var(\bar{X}\_{n}) = Var\left (\frac{X_{1}+X_{2}+\cdots + X_{n}}{n} \right)$이고 $X_{j}$는 서로 **독립**이므로 **공분산** 항은 존재하지 않는다. 따라서 $Var(\bar{X}\_{n})$은 $\frac{1}{n^{2}} \cdot n\sigma^{2}$와 같다.

* * * 
<br>

# 2. 중심극한정리

- [**정의와 증명**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_29/#%EC%A0%95%EC%9D%98%EC%99%80-%EC%A6%9D%EB%AA%85)
- [**이항분포의 정규분포 근사**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_29/#%EC%9D%B4%ED%95%AD%EB%B6%84%ED%8F%AC%EC%9D%98-%EC%A0%95%EA%B7%9C%EB%B6%84%ED%8F%AC-%EA%B7%BC%EC%82%AC)


## 정의와 증명

서로 **독립**이고 **동일한 확률분포**를 따르는 확률변수 $X_{1}, \cdots , X_{n}$에 대하여, $E(X_{j}) = \mu$이고 $Var(X_{j}) = \sigma^{2}$를 가정한다. 이 때 $n \rightarrow \infty$이면 $\frac{\sum_{j=1}^{n}X_{j}-n\mu}{\sqrt{n}\sigma}$는 **표준정규분포** $N(0, 1)$로 **수렴**한다. 여기서 $\frac{\sum_{j=1}^{n}X_{j}-n\mu}{\sqrt{n}\sigma}$는 **평균**과 **분산**이 각각 $0$과 $1$이다.

\begin{align}
E \left( \frac{\sum_{j=1}^{n}X_{j}-n\mu}{\sqrt{n}\sigma} \right) = \frac{1}{\sqrt{n}\sigma} \left\[ E \Big( \sum_{j=1}^{n} X_{j} \Big) -n\mu \right\] = \frac{1}{\sqrt{n}\sigma}(n\mu - n\mu) = 0 \nonumber  
\end{align}

\begin{align}
Var \left( \frac{\sum_{j=1}^{n}X_{j}-n\mu}{\sqrt{n}\sigma} \right) = \frac{1}{n\sigma^{2}} \left\[ Var \Big( \sum_{j=1}^{n} X_{j} -n\mu \Big) \right\] = \frac{1}{n\sigma^{2}}(n\sigma^{2} + 0) = 1 \nonumber  
\end{align}

**중심극한정리**의 증명은 **적률생성함수**를 이용한다. $X_{j}$를 **표준화** 과정을 거친 확률변수이고, $X_{j}$의 MGF인 $M_{X}(t)$가 존재한다고 가정한다. 표준화 된 확률변수의 **평균** $\mu$는 $0$이고 **분산** $\sigma^{2}$는 $1$이 된다. 따라서 이제는 $\frac{\sum_{j=1}^{n}X_{j}}{\sqrt{n}}$이 $N(0, 1)$로 수렴한다는 사실을 보이면 된다. $S_{n} = \sum_{j=1}^{n}X_{j}$로 놓으면, $\frac{S_{n}}{\sqrt{n}}$의 MGF가 $N(0, 1)$의 MGF로 수렴한다는 사실을 보임으로써 중심극한정리를 증명한다.

\begin{align}
E \left( e^{t \cdot \frac{S_{n}}{\sqrt{n}}}\right) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= E \left( e^{t \cdot \frac{X_{1}+X_{2}+ \cdots + X_{n}}{\sqrt{n}}} \right) \\\\\\ \\\\\\
&= E \left( e^{t \cdot \frac{X_{1}}{\sqrt{n}}} \right) \times E \left( e^{t \cdot \frac{X_{2}}{\sqrt{n}}} \right) \times \cdots \times E \left( e^{t \cdot \frac{X_{n}}{\sqrt{n}}} \right) \\\\\\ \\\\\\
&= \Bigg\[ M_{X} \left( \frac{t}{\sqrt{n}}\right) \Bigg\]^{n}
\end{aligned}
\end{equation\*}

$X_{j}$가 서로 **독립**이라는 점을 이용하여 기댓값을 개별 확률변수에 대한 기댓값들의 곱의 형태로 변환하였다. $n \rightarrow \infty$이면 $\frac{t}{\sqrt{n}} \rightarrow 0$이므로 $\Big\[ M_{X} \left( \frac{t}{\sqrt{n}}\right) \Big\]^{n}$는 $\Big\[M(0) \Big\]^{\infty}$ 꼴 즉, $1$의 무한 제곱 꼴이 된다. 따라서 **로그**를 취해 본다.

\begin{align}
\lim_{n \rightarrow \infty} \log \Bigg\[ M_{X} \left( \frac{t}{\sqrt{n}}\right) \Bigg\]^{n} \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= \lim_{n \rightarrow \infty} n \cdot \log M_{X} \left( \frac{t}{\sqrt{n}}\right) \\\\\\ \\\\\\
&= \lim_{n \rightarrow \infty} \frac{\log M_{X} \left( \frac{t}{\sqrt{n}}\right)}{1/n} \\\\\\ \\\\\\
&= \lim_{y \rightarrow 0} \frac{\log M_{X} (ty)}{y^{2}}, \quad y=\frac{1}{\sqrt{n}}
\end{aligned}
\end{equation\*}

이제 **로피탈의 정리**를 사용한다. 로피탈의 정리에 의해, $f(x)$와 $g(x)$가 $c$를 포함한 구간에서 **연속**이고, **미분 가능**하면 $\lim_{x \rightarrow c} \frac{f(x)}{g(x)} = \lim_{x \rightarrow c} \frac{f^{\prime}(x)}{g^{\prime}(x)}$가 성립한다.

\begin{equation\*}
\begin{aligned}
&= \lim\_{y \rightarrow 0} \frac{ t \cdot M\_{X}^{\prime} (ty)}{2y \cdot M\_{X}(ty)} \\\\\\ \\\\\\
&= \lim\_{y \rightarrow 0} \frac{ t \cdot M\_{X}^{\prime} (ty)}{2y} \\\\\\ \\\\\\
& \because y \rightarrow 0 \Rightarrow M\_{X}(ty) = M\_{X}(0) = 1
\end{aligned}
\end{equation\*}

한편, $n \rightarrow \infty$이면 $M^{\prime}_{X}(ty) = M^{\prime}\_{X}\left(\frac{t}{\sqrt{n}}\right) \rightarrow M^{\prime}\_{X}(0)$이다. $M^{\prime}\_{X}(0) = E(X)$이므로 $0$과 같다. 여전히 $\frac{0}{0}$ 꼴이기 때문에 한 번 더 **로피탈의 정리**를 사용한다. 

\begin{equation\*}
\begin{aligned}
&= \lim\_{y \rightarrow 0} \frac{ t^{2} \cdot M\_{X}^{\prime\prime} (ty)}{2} \\\\\\ \\\\\\
&= \frac{t^{2}}{2} \lim\_{y \rightarrow 0} M\_{X}^{\prime\prime} (ty) \\\\\\ \\\\\\
&= \frac{t^{2}}{2}
\end{aligned}
\end{equation\*}

$n \rightarrow \infty$이면 $M^{\prime\prime}_{X} (ty) = M\_{X}^{\prime\prime}\left(\frac{t}{\sqrt{n}}\right) \rightarrow M^{\prime\prime}\_{X}(0)$이다. $M^{\prime\prime}\_{X}(0) = E(X^{2})$이므로 $1$과 같다. $E(X^{2}) = Var(X) - \[E(X)\]^{2}$이고 $X$의 분산은 $1$이기 때문이다.

처음에 로그를 취했기 때문에 계산이 끝난 후에는 로그를 복구해야 한다. 따라서 $E \left( e^{t \cdot \frac{S_{n}}{\sqrt{n}}}\right) = \Big\[ M_{X} \left( \frac{t}{\sqrt{n}}\right) \Big\]^{n} = e^{\frac{1}{2}t^{2}}$이다. 그런데 $e^{\frac{1}{2}t^{2}}$는 **표준정규분포**를 따르는 확률변수의 [적률생성함수](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_17/#%ED%91%9C%EC%A4%80%EC%A0%95%EA%B7%9C%EB%B6%84%ED%8F%AC)와 같으므로 이로써 중심극한정리가 증명된다.


## 이항분포의 정규분포 근사

$X \sim Bin(n, p)$이면 $X_{j} \overset{i.i.d} \sim Bern(p)$에 대하여 $X = \sum X_{j}$이다. **중심극한정리**에 의해, $n \rightarrow \infty$이면 $\frac{\sum{X_{j}}-nE(X_{j})}{\sqrt{n \cdot Var(X_{j})}} = \frac{X-np}{\sqrt{npq}} \rightarrow N(0, 1)$이 성립한다.

따라서 $P(a \leq X \leq b) = P\left(\frac{a-np}{\sqrt{npq}} \leq \frac{X-np}{\sqrt{npq}} \leq \frac{b-np}{\sqrt{npq}}\right)$는 $n \rightarrow \infty$에 따라 $\Phi\left(\frac{b-np}{\sqrt{npq}} \right ) - \Phi\left(\frac{a-np}{\sqrt{npq}} \right )$로 근사한다.

**이항분포**의 **포아송분포 근사**와 **정규분포 근사**를 비교하면, 포아송분포 근사는 $n$이 매우 크고 $p$가 매우 작은 경우에 적절하다. 반면 정규분포 근사는 $n$이 매우 크고 $p$가 $\frac{1}{2}$에 가까울수록 적절하다. $p$가 $\frac{1}{2}$에 가깝다면 $n$의 크기가 상대적으로 작더라도 정규분포 근사를 통해 비교적 정확한 근삿값을 얻어낼 수 있다.

그러나 $p$가 $\frac{1}{2}$로부터 멀리 떨어져 있을수록 이항분포의 그래프는 한쪽으로 치우친 형태로 나타나게 되는데 이는 $n$의 값이 상당히 큰 수준이 아니라면 정규분포 근사로 오차가 작은 근삿값을 얻어내기 어렵다는 것을 의미한다. 반대로 $p$가 정확히 $\frac{1}{2}$라면 이항분포의 그래프도 대칭형으로 나타나기 때문에 작은 $n$의 값으로도 빠르게 정규분포 근사가 이루어진다.

이항분포의 정규분포 근사는 **이산확률분포**를 **연속확률분포**로 근사하는 과정이다. 따라서 경우에 따라 약간의 문제가 발생할 수 있는데 예를 들어, $P(a \leq X \leq b)$에서 $a$와 $b$의 값이 같다면 결국 $P(X = a)$와 같다. 그런데 이를 정규분포 근사를 이용하여 계산하면 값이 $0$이 되어 의미 있는 결과값을 얻을 수 없다. 그렇기 때문에 정규분포 근사 이전, 약간의 수정이 필요하다. 만약 $a$가 정수라면 $P(X=a)$를 $P\left(a-\frac{1}{2} < X < a+\frac{1}{2}\right)$와 같은 형태로 변환할 수 있다. $X$가 이산확률변수이기 때문에 두 확률은 서로 일치한다. 이와 같은 과정을 정규분포 근사에서 **연속성 수정**이라 한다.
