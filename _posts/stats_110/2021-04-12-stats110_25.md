---
title:  "확률론 기초(Stats 110) : Lesson 25. Gamma Distribution, Beta Distribution and Order Statistics"
excerpt: "하버드 대학교 조셉 K. 블리츠타인 교수의 Stats 110 25강 정리"

categories:
  - 통계학
  - 확률론
tags:
  - 감마분포
  - 베타분포
  - 순서통계량
use_math: true
comments: true
last_modified_at: 2021-04-12T23:30:00
header:
  image: /assets/images/texture.jpg
---

<img src="/assets/images/stats_110/lesson_25.jpg" width="80%" height="80%" title="height" alt="height"/> 

# 1. 감마분포

- [**감마분포의 가법성**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_25/#%EA%B0%90%EB%A7%88%EB%B6%84%ED%8F%AC%EC%9D%98-%EA%B0%80%EB%B2%95%EC%84%B1)
- [**감마분포와 베타분포의 관계**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_25/#%EA%B0%90%EB%A7%88%EB%B6%84%ED%8F%AC%EC%99%80-%EB%B2%A0%ED%83%80%EB%B6%84%ED%8F%AC%EC%9D%98-%EA%B4%80%EA%B3%84)


## 감마분포의 가법성

은행에서 차례를 기다린 시간을 확률변수 $X$라 하고 $X \sim Gamma(a, \lambda)$라 가정한다. 또한, 우체국에서 차례를 기다린 시간을 확률변수 $Y$라 하고 $Y \sim Gamma(b, \lambda)$라 가정한다. 그리고 $X, Y > 0$이 성립하고 서로 **독립**이며 $a$와 $b$가 모두 **양의 정수**라고 가정한다.

만약 $a=5$라면 나의 순서 앞에 이미 $5$명이 있는 상황을 의미한다. 그리고 각각의 사람이 볼일을 마칠 때까지 걸리는 시간은 [감마분포와 지수분포의 관계](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_24/#%EA%B0%90%EB%A7%88%EB%B6%84%ED%8F%AC%EC%99%80-%EC%A7%80%EC%88%98%EB%B6%84%ED%8F%AC%EC%9D%98-%EA%B4%80%EA%B3%84)에 따라 $Expo(\lambda)$을 따를 것이다.

은행과 우체국에서 기다린 총 시간을 $T$라 할 때, $T=X+Y$가 성립한다. 그런데 $X, Y \overset{i.i.d} \sim Expo(\lambda)$이고 $X$와 $Y$가 독립이므로 $T$는 결국 동일한 **지수분포**를 따르는 독립적인 확률변수 $a+b$개 값의 총합과 같다. 따라서 $T \sim Gamma(a+b, \lambda)$이다.

이 성질은 $a$와 $b$가 정수가 아닌 경우에도 성립한다. 증명은 **적률생성함수**를 이용한다. 감마분포를 따르는 확률변수의 [적률생성함수](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_24/#%ED%8F%AC%EC%95%84%EC%86%A1-%EA%B3%BC%EC%A0%95) 유도 과정은 링크를 참조한다.

\begin{align}
M_{T}(t) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= E(e^{tT}) \\\\\\ \\\\\\
&= E(e^{t(X+Y)}) \\\\\\ \\\\\\
&= E(e^{tX}) \cdot E(e^{tY}) \\\\\\ \\\\\\
&= \frac{1}{(1+\frac{t}{\lambda})^{a}} \cdot \frac{1}{(1+\frac{t}{\lambda})^{b}} \\\\\\ \\\\\\
&= \frac{1}{(1+\frac{t}{\lambda})^{a+b}} \\\\\\ \\\\\\
&\therefore T \sim Gamma(a+b, \lambda)
\end{aligned}
\end{equation\*}


## 감마분포와 베타분포의 관계

이제 새로운 확률변수 $W= \frac{X}{X+Y}$를 설정한다. $W$는 기다린 총 시간 중 은행에서 기다린 시간의 비중을 나타낸다. 이제 총 대기 시간 $T$와 $W$의 **독립** 여부를 확인한다. 만약 $T, W$의 **결합 PDF**가 각각의 PDF를 곱한 것과 일치한다면 독립이 성립할 것인다. 즉, $f_{T, W}(t, w) = f_{T}(t) \cdot f_{W}(w)$가 성립하면 $T$와 $W$는 독립이다. 또한 $T$와 $W$ 모두 $X$와 $Y$에 대한 식으로 표현 가능하므로 $T, W$의 결합 PDF는 $X, Y$의 결합 PDF로부터의 [다차원 변수변환](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_22/#%EB%8B%A4%EC%B0%A8%EC%9B%90-%EB%B3%80%EC%88%98%EB%B3%80%ED%99%98)을 통해 얻어낼 수 있다. 그 과정은 다음과 같다.

\begin{align}
f_{T, W}(t, w) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= f_{X, Y}(x, y) 
  \begin{Vmatrix}
  \frac{\partial x}{\partial t} & \frac{\partial x}{\partial w}\\\\\\ 
  \frac{\partial y}{\partial t} & \frac{\partial y}{\partial w}
  \end{Vmatrix}   \\\\\\ \\\\\\
&= f_{X}(x) \cdot f_{Y}(y)
  \begin{Vmatrix}
  \frac{\partial x}{\partial t} & \frac{\partial x}{\partial w}\\\\\\ 
  \frac{\partial y}{\partial t} & \frac{\partial y}{\partial w}
  \end{Vmatrix}   \\\\\\ \\\\\\
&= \frac{\lambda^{a} \cdot \lambda^{b}}{\Gamma(a) \cdot \Gamma(b)} \cdot x^{a-1} e^{-\lambda x} \cdot y^{b-1} e^{-\lambda y} 
  \begin{Vmatrix}
  \frac{\partial x}{\partial t} & \frac{\partial x}{\partial w}\\\\\\ 
  \frac{\partial y}{\partial t} & \frac{\partial y}{\partial w}
  \end{Vmatrix}   \\\\\\ \\\\\\
&= \frac{\lambda^{a} \cdot \lambda^{b}}{\Gamma(a) \cdot \Gamma(b)} \cdot x^{a-1} e^{-\lambda x} \cdot y^{b-1} e^{-\lambda y} 
  \begin{Vmatrix}
  w & t \\\\\\ 
  1-w & -t
  \end{Vmatrix} \\\\\\ \\\\\\
&= \frac{\lambda^{a} \cdot \lambda^{b}}{\Gamma(a) \cdot \Gamma(b)} \cdot x^{a-1} e^{-\lambda x} \cdot y^{b-1} e^{-\lambda y} \cdot \left | -t \right | \\\\\\ \\\\\\
&= \frac{\lambda^{a} \cdot \lambda^{b}}{\Gamma(a) \cdot \Gamma(b)} \cdot x^{a-1} e^{-\lambda x} \cdot y^{b-1} e^{-\lambda y} \cdot t
\end{aligned}
\end{equation\*}

$t=x+y$이고 $w=\frac{x}{x+y}$이므로 $x$와 $y$에 대하여 식을 정리하고 대입하면 $x=tw, \; y=t(1-w)$이다. 이를 이용하여 **자코비안**을 계산한다. 그 결과는 $\mid -t \mid$인데 $x$와 $y$가 모두 양수이므로 $x+y = t$ 또한 양수가 되어 자코비안은 $t$이다. 

자코비안 계산 후, $x=tw, \; y=t(1-w)$이라는 점을 이용하여 위 식을 $t$와 $w$에 관한 식으로 변환한다.

\begin{align}
f_{T, W}(t, w) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= \frac{\lambda^{a} \cdot \lambda^{b}}{\Gamma(a) \cdot \Gamma(b)} \cdot (tw)^{a-1} e^{-\lambda tw} \cdot \[t(1-w)\]^{b-1} e^{-\lambda t(1-w)} \cdot t \\\\\\ \\\\\\
&= \frac{\lambda^{a} \cdot \lambda^{b}}{\Gamma(a) \cdot \Gamma(b)} \cdot w^{a-1}(1-w)^{b-1} \cdot t^{a+b-1} \cdot e^{-\lambda t}
\end{aligned}
\end{equation\*}

결과물이 $t$에 관한 함수와 $w$에 관한 함수의 곱과 같으므로 $T$와 $W$는 **독립**이다. 이제 $W$의 **주변분포**를 계산하면 다음과 같다.

\begin{align}
f_{W}(w) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= \int_{-\infty}^{\infty} f_{T, W}(t, w) \; dt \\\\\\ \\\\\\
&= \frac{\lambda^{a} \cdot \lambda^{b}}{\Gamma(a) \cdot \Gamma(b)} \cdot w^{a-1}(1-w)^{b-1} \int_{-\infty}^{\infty} t^{a+b-1} \cdot e^{-\lambda t} \; dt \\\\\\ \\\\\\
&= \frac{\Gamma(a+b)}{\Gamma(a) \cdot \Gamma(b)} \cdot w^{a-1}(1-w)^{b-1} \left( \frac{\lambda^{(a+b)}}{\Gamma(a+b)} \int_{0}^{\infty} t^{a+b-1} \cdot e^{-\lambda t} \; dt \right) \\\\\\ \\\\\\
&= \frac{\Gamma(a+b)}{\Gamma(a) \cdot \Gamma(b)} \cdot w^{a-1}(1-w)^{b-1}
\end{aligned}
\end{equation\*}

식을 정리하는 과정에서 큰 괄호로 묶인 부분은 $Gamma(a+b, \lambda)$의 PDF를 전체 구간에서 적분한 값이므로 $1$이 됨을 확인할 수 있다. 그리고 앞부분은 **베타분포**의 PDF 형태와 같다. 여기서 베타함수의 **정규화상수** $c$가 $\frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)}$와 같다는 사실을 확인할 수 있다.

결과를 정리하면, $T \sim Gamma(a+b, 1)$이고 $W \sim Beta(a, b)$이며 $T$와 $W$는 **독립**이다. 이는 반드시 $X$와 $Y$가 모두 **감마분포**를 따를 때에만 성립한다.

마지막으로, $W$의 **기댓값**을 살펴보면 $T$와 $W$가 **독립**이므로 $E(W) \cdot E(T) = E(WT)$가 성립한다. $T=X+Y$이고 $W=\frac{X}{X+Y}$이므로 $E \left( \frac{X}{X+Y} \right) \cdot E(X+Y) = E \left( \frac{X}{X+Y} \cdot (X+Y) \right) = E(X)$를 만족한다.

따라서 $\frac{E(X)}{E(X+Y)} = E \left( \frac{X}{X+Y} \right) = E(W)$이 성립한다. $E(X)$와 $E(Y)$는 각각 **감마분포**를 따르는 확률변수의 기댓값이므로 $E(X) = a, \; E(Y) = b$이다. 결국 $W \sim Beta(a, b)$일 때, $E(W) = \frac{a}{a+b}$이다.

* * * 
<br>

# 2. 순서통계량

- [**순서통계량의 정의**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_25/#%EC%88%9C%EC%84%9C%ED%86%B5%EA%B3%84%EB%9F%89%EC%9D%98-%EC%A0%95%EC%9D%98)
- [**누적분포함수**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_25/#%EB%88%84%EC%A0%81%EB%B6%84%ED%8F%AC%ED%95%A8%EC%88%98)
- [**확률밀도함수**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_25/#%ED%99%95%EB%A5%A0%EB%B0%80%EB%8F%84%ED%95%A8%EC%88%98)
- [**순서통계량 예제**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_25/#%EC%88%9C%EC%84%9C%ED%86%B5%EA%B3%84%EB%9F%89-%EC%98%88%EC%A0%9C)


## 순서통계량의 정의

확률변수 $X_{1}, X_{2}, \cdots , X_{n}$이 서로 **독립**이며 **동일한 확률분포**를 따를 때 이 확률변수들을 **크기 순**으로 늘어놓음으로써 얻어 낸 새로운 확률변수들을 **순서통계량**이라 한다.

순서통계량은 $X_{(k)}$와 같이 표기하며 $k$번째로 작은 확률변수를 의미한다. 순서통계량의 의미에 따라 $X_{(1)} \leq X_{(2)} \leq \cdots \leq X_{(n)}$이 성립한다.

확률변수 $X_{1}, X_{2}, \cdots X_{n}$는 서로 **독립**이지만 순서통계량 $X_{(1)}, X_{(2)}, \cdots , X_{(n)}$는 서로 **종속**이다. 예를 들어, $X_{(1)} = 2$라면 $X_{(2)}$부터는 적어도 $2$보다 크거나 같다는 사실을 알아낼 수 있기 때문이다.

이처럼 순서통계량은 독립이 성립하지 않고 특히 이산확률변수의 경우 동점이 되는 상황까지 고려해야 해서 다루기가 매우 까다롭다. 따라서 본 포스트에서는 동점을 고려하지 않기 위해 $X_{j}$가 **연속확률변수**임을 가정한다.


## 누적분포함수

순서통계량의 **누적분포함수** 즉, $P(X_{(j)} \leq x)$는 적어도 $n$개의 확률변수 값 중에서 $j$개의 확률변수 값이 $x$보다 작거나 같을 확률을 의미한다. 이를 시각화하면 아래와 같다.

<img src="/assets/images/stats_110/lesson_25_1.jpg" width="40%" height="40%" title="example1" alt="example1"/>

그림의 빨간 구간에는 최소 $0$개부터 최대 $n-j$개의 확률변수가 존재할 수 있다. 따라서 $P(X_{(j)} \leq x)$는 $x$를 기준으로 왼쪽에 $j$개의 확률변수가 존재할 확률부터 $n$개의 확률변수가 존재할 확률까지 총 $n-j+1$개의 **배반 사건**의 발생 확률의 합과 같다. 

또한 $x$를 기준으로 각 확률변수가 $x$의 왼쪽에 위치하는 사건을 성공, 오른쪽에 위치하는 사건을 실패의 두 가지 경우로 나눌 수 있고, 각 확률변수는 서로 **독립적**이므로 개별 배반 사건의 발생 확률은 **이항확률**로 표현 가능하다. $n-j+1$개의 배반 사건의 발생 확률을 모두 더한 결과값은 순서통계량의 CDF가 된다. 수식으로 표현하면 다음과 같다.

\begin{align}
P(X_{(j)} \leq x) = \sum_{k=j}^{n} \binom{n}{k} \Big\[P(X \leq x) \Big\]^{k} \cdot \Big\[P(X > x) \Big\]^{n-k} = \sum_{k=j}^{n} \binom{n}{k} \Big\[F(x) \Big\]^{k} \cdot \Big\[1-F(x) \Big\]^{n-k} \nonumber
\end{align}


## 확률밀도함수

이제 순서통계량의 **확률밀도함수**인 $f_{X_{(j)}}(x)$를 계산한다. 순서통계량의 CDF를 알고 있는 상태이므로 이를 **미분**하면 확률밀도함수 또한 얻어낼 수 있다. 하지만 계산이 복잡하므로 다른 접근 방법을 사용한다.

<img src="/assets/images/stats_110/lesson_25_2.jpg" width="40%" height="40%" title="example2" alt="example2"/>

그림과 같이 하나의 확률변수가 $x$를 포함하는 아주 작은 구간인 $dx$ 안에 존재하는 상황을 가정한다. 그렇게 되면 구간의 왼쪽에는 $j-1$개의 확률변수가 존재하며 구간의 오른쪽에는 $n-j$개의 확률변수가 존재할 것이다.

PDF에 아주 작은 구간에 해당하는 **증분**을 곱하면 확률변수가 해당 구간 내에 존재할 확률이 된다. 따라서 $X_{(j)}$가 아주 작은 구간 내에 위치하게 될 확률은 $f_{X_{(j)}}(x) \cdot dx$와 같다. 이 확률은 아주 작은 구간 내 하나의 확률변수가 존재하고, 구간의 좌우로 각각 확률변수가 $j-1$개와 $n-j$가 존재할 확률과 같다. 이를 수식으로 표현하면 다음과 같다.

\begin{align}
f_{X_{(j)}}(x) \cdot dx = n \cdot \binom{n-1}{j-1}\Big\[F(x)\Big\]^{j-1} \cdot \Big\[1-F(x)\Big\]^{n-j} \cdot f_{X}(x) \cdot dx \nonumber
\end{align}

\begin{align}
\therefore f_{X_{(j)}}(x) = n \cdot \binom{n-1}{j-1}\Big\[F(x)\Big\]^{j-1} \cdot \Big\[1-F(x)\Big\]^{n-j} \cdot f_{X}(x) \nonumber
\end{align}

위 식을 풀어서 해석하면 좌변은 $j$번째로 작은 확률변수가 $x$를 포함한 아주 작은 구간 내에 위치할 확률을 의미한다. $j$번째로 올 수 있는 확률변수는 $X_{1}$부터 $X_{n}$까지 모두 가능하기 때문에 특정 확률변수가 $X_{(j)}$가 될 확률에 $n$을 곱해야 한다. 우변의 $n$은 그러한 의미에서 곱해졌다.

그 다음 확률변수가 특정되었을 때 $x$의 왼쪽에 $j-1$개의 확률변수가 위치하고 오른쪽에 $n-j$개의 확률변수가 위치할 확률이 곱해졌다. 이 확률은 순서통계량의 CDF를 계산할 때와 마찬가지로 **이항확률**로 나타난다. 마지막으로 특정된 원소를 아주 작은 구간 내에 위치시켜야 하므로 $f_{X}(x) \cdot dx$를 곱한다. 이제 양변의 $dx$를 없애고 나면 순서통계량의 PDF를 얻을 수 있다.


## 순서통계량 예제

> $U_{1}, U_{2} \overset{i.i.d} \sim Unif(0, 1)$일 때, $E(\mid U_{1}-U_{2} \mid)$의 값은?

이 문제는 앞서 [다변수 확률변수](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_19/#%EB%8B%A4%EB%B3%80%EC%88%98-%ED%99%95%EB%A5%A0%EB%B3%80%EC%88%98-%EC%98%88%EC%A0%9C)에 대한 예제로 다루어진 문제이지만 이번에는 **순서통계량**을 통한 접근으로 문제를 해결해 본다.

우선, $U_{1}, U_{2}, \cdots, U_{n} \overset{i.i.d} \sim Unif(0, 1)$이면 $f_{U_{(j)}}(u)$는 다음과 같다.

\begin{align}
f_{U_{(j)}}(u) = n \binom{n-1}{j-1} \cdot x^{j-1} (1-x)^{n-j} \cdot 1, \quad 0 < x < 1 \nonumber
\end{align}

$Unif(0, 1)$의 PDF와 CDF는 각각 $1$과 $x$이므로 위와 같은 식을 얻을 수 있다. 여기서 $n \binom{n-1}{j-1}$는 **상수**이므로 결국 **베타분포**의 PDF와 같은 형태임을 알 수 있다. 따라서 $U_{(j)} \sim Beta(j, n-j+1)$이다.

이전에 $E(\mid U_{1}-U_{2} \mid)$는 $E(M)-E(m)$과 같음을 확인하였다. $M$은 두 확률변수 중에서 큰 값, $m$은 작은 값에 해당하므로 $U_{(1)} = m = Beta(1, 2)$이고 $U_{(2)} = M = Beta(2, 1)$이 성립한다.

$Beta(a, b)$을 따르는 확률변수의 **기댓값**은 $\frac{a}{a+b}$와 같다. 따라서 $E(M)-E(m) = \frac{2}{1+2} - \frac{1}{1+2}$이다. 계산 결과는 $\frac{1}{3}$으로, 이전의 계산 결과와 일치한다.

