---
title:  "확률론 기초(Stats 110) : Lesson 21. Covariance and Correlation"
excerpt: "하버드 대학교 조셉 K. 블리츠타인 교수의 Stats 110 21강 정리"

categories:
  - 통계학
  - 확률론
tags:
  - 분산
  - 공분산
  - 상관계수
use_math: true
comments: true
last_modified_at: 2021-03-23T23:30:00
header:
  image: /assets/images/texture.jpg
---

<img src="/assets/images/stats_110/lesson_21.jpg" width="80%" height="80%" title="direction" alt="direction"/> 

# 1. 공분산과 상관계수

- [**공분산**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_21/#%EA%B3%B5%EB%B6%84%EC%82%B0)
- [**상관계수**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_21/#%EC%83%81%EA%B4%80%EA%B3%84%EC%88%98)
- [**이산확률변수의 분산**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_21/#%EC%9D%B4%EC%82%B0%ED%99%95%EB%A5%A0%EB%B3%80%EC%88%98%EC%9D%98-%EB%B6%84%EC%82%B0)


## 공분산

두 확률변수 $X$와 $Y$의 **공분산**은 다음과 같이 정의된다.
- $Cov(X, Y) = E\Big\[(X-E(X))(Y-E(Y))\Big\]$

만약 임의적으로 생성된 표본에서 대부분의 $x$값이 평균 이상이고 $y$값 또한 그러한 양상을 띈다면, 양수 곱하기 양수의 꼴이므로 공분산이 양수가 될 것이다. 마찬가지로 대부분의 $x$값이 평균 이하이고 $y$값도 그러한 양상을 띈다면 음수 곱하기 음수의 꼴이므로 역시 공분산이 양수가 된다.

반대로 임의적으로 생성된 표본에서 대부분의 $x$값은 평균 이하이지만 $y$값은 평균 이상이라면, 음수 곱하기 양수의 꼴이므로 공분산이 음수가 될 것이다. 마찬가지로 대부분의 $x$값이 평균 이상이지만 $y$값은 평균 이하라면 양수 곱하기 음수의 꼴이므로 역시 공분산이 음수가 된다.

공분산의 여러가지 성질은 다음과 같다.

- $Cov(X, X) = Var(X)$

공분산의 계산식에서 $Y$ 대신 $X$를 대입하면 분산의 계산식과 동일해진다.

- $Cov(X, Y) = Cov(Y, X)$

공분산의 **대칭성**으로, 확률변수의 연산은 **교환법칙**이 성립하기 때문에 순서를 바꾸어도 계산 결과는 동일하다.

- $Cov(X, Y) = E(XY) - E(X)E(Y)$

공분산의 계산식을 전개하고 기댓값의 선형성을 이용하면 양변이 일치함을 쉽게 확인할 수 있다.

- $Cov(X, c) = 0, \quad c \in R$

상수의 경우 $c=E(c)$이므로 공분산이 $0$이 된다.

- $Cov(cX, Y) = E(cXY) - E(cX)E(Y) = c \cdot (E(XY) - E(X)E(Y)) = c \cdot Cov(X, Y)$

확률변수에 붙어 있는 상수는 공분산 바깥으로 빼낼 수 있다. 그러나 분산과는 다르게 공분산 바깥으로 빠져 나오면서 상수에 제곱이 되지 않고 그대로 빠져 나온다.

- $Cov(X, Y+Z) = Cov(X, Y) + Cov(X, Z)$
- $Cov(X+Y, Z+W) = Cov(X, Z) + Cov(X, W) + Cov(Y, Z) + Cov(Y, W)$
- $Cov\left(\sum_{i=1}^{m}a_{i}X_{i}, \sum_{j=1}^{n}b_{j}Y_{j}\right) = \sum_{i, j}a_{i}b_{j}Cov(X_{i}, Y_{j})$

\begin{align}
Cov(X, Y+Z) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= E(X(Y+Z)) - E(X)E(Y+Z) \\\\\\ \\\\\\
&= E(XY)-E(X)E(Y)+E(XZ)-E(X)E(Z) \\\\\\ \\\\\\
&= Cov(X, Y) + Cov(X, Z)
\end{aligned}
\end{equation\*}

공분산의 경우 하나의 확률변수를 고정한 상태에서 다른 확률변수들에 대한 **선형성**이 성립한다. 위와 같이 공분산의 계산식을 전개하면 쉽게 증명된다. 마지막 성질은 공분산의 선형성을 일반화한 것이다.

- $Var(X+Y) = Var(X) + Var(Y) + 2Cov(X, Y)$

\begin{align}
Var(X+Y) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= E\\\{(X+Y)^{2}\\\} - \\\{E(X+Y)\\\}^{2} \\\\\\ \\\\\\
&= E(X^{2} + 2XY + Y^{2}) - (E(X)^{2} + 2E(X)E(Y) + E(Y)^{2}) \\\\\\ \\\\\\
&= E(X^{2}) - \\\{E(X)\\\}^{2} + E(Y^{2}) - \\\{E(Y)\\\}^{2} + 2E(XY) - 2E(X)E(Y)) \\\\\\ \\\\\\
&= Var(X) + Var(Y) + 2Cov(X, Y)
\end{aligned}
\end{equation\*}

일반적으로 두 확률변수 합의 분산은 기댓값과는 달리 선형성이 성립하지 않는다. 공분산 항이 추가되기 때문이다. 그런데 확률변수 $X$와 $Y$가 **독립**이라면 $E(XY)=E(X)E(Y)$가 성립하여 공분산이 $0$이 된다. 따라서 이 경우에는 $Var(X+Y)=Var(X)+Var(Y)$가 성립한다.

- $X$와 $Y$가 **독립**이면 $Cov(X, Y) = 0$이지만 역은 성립하지 않음

역명제의 반례는 $Z \sim N(0, 1)$이고, $X=Z, \;\; Y=Z^{2}$인 경우이다. 이 경우 $X$와 $Y$는 독립이 아니다. 한 확률변수 값에 대한 정보로 다른 확률변수의 값을 추론할 수 있기 때문이다. 그런데 $Cov(X, Y) = E(Z^{3}) - E(Z)E(Z^{2}) = 0$이다. $Z$의 홀수 차수 적률은 모두 $0$이기 때문이다. 따라서 공분산이 $0$인 경우라도 두 확률변수가 독립이 아닌 경우가 존재한다. 이와 같은 경우 두 확률변수는 독립이 아닌 **비상관**이다.


## 상관계수

**상관계수**는 공분산을 **표준화**한 것이다. 두 확률변수에 대한 상관계수는 다음과 같이 정의된다.

- $Corr(X, Y) = Cov\left(\frac{X-E(X)}{\sigma_{X}}, \frac{Y-E(Y)}{\sigma_{Y}}\right) = \frac{Cov(X, Y)}{\sigma_{X}\sigma_{Y}}$

위 식에서 상수 더하기에 해당하는 $E(X)$와 $E(Y)$는 공분산에 영향을 미치지 않고, 상수 곱하기에 해당하는 $\sigma_{X}$와 $\sigma_{Y}$는 공분산의 성질에 의해 공분산 밖으로 빼낼 수 있다.

상관계수는 항상 $-1 \leq Corr(X, Y) \leq 1$을 만족한다. 어떤 두 확률변수를 각각 평균은 $0$이고 분산은 $1$이 되도록 **표준화**한 확률변수를 $X$와 $Y$라고 정의한다. 표준화된 확률변수는 분산이 $1$이므로 공분산과 상관계수가 일치하게 된다. 즉, $Cov(X, Y) = Corr(X, Y) = \rho$이다. 이제 두 확률변수 합과 차의 분산을 계산한다.

\begin{align}
Var(X+Y) = 2 + \rho, \quad Var(X-Y) = 2 - \rho \nonumber
\end{align}

분산은 항상 $0$보다 크거나 같아야 하므로 $2 + \rho \geq 0$과 $2 - \rho \geq 0$이 모두 성립해야 한다. 두 부등식을 $\rho$에 대하여 정리하면 $-1 \leq \rho \leq 1$이라는 결론을 얻을 수 있다.


## 이산확률변수의 분산

> 이항분포

$X \sim Bin(n, p)$이면, $X=X_{1} + X_{2} + \cdots + X_{n}$이고 $X_{j} \overset{i.i.d} \sim Bern(p)$가 성립한다. 이 경우에 **이항분포**를 따르는 확률변수 $X$의 분산 계산은 다음과 같다.

\begin{align}
Var(X) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= Var(X_{1} + X_{2} + \cdots + X_{n}) \\\\\\ \\\\\\
&= Var(X_{1}) + Var(X_{2}) + \cdots Var(X_{n}) + 2Cov(X_{1}, X_{2}) + 2Cov(X_{1}, X_{3} + \cdots + 2Cov(X_{n-1}, X_{n}) \\\\\\ \\\\\\
&= n \cdot Var(X_{1}) = np(1-p)
\end{aligned}
\end{equation\*}

위 과정에서 **공분산** 항은 모두 $0$이 된다. 베르누이 확률변수들이 모두 **독립적이고 동일한 확률분포**를 따르기 때문이다. 따라서 하나의 베르누이 확률변수의 분산에 $n$을 곱한 것이 이항확률변수 $X$의 분산이 된다. 베르누이 확률변수의 분산은 $p(1-p)$이므로 이항확률변수의 분산은 $np(1-p)$가 된다.

> 다항분포

$\overset{\rightarrow} X \sim Mult(n, \overset{\rightarrow} p)$일 때, $Cov(X_{i}, X_{j})$는 다음과 같이 계산된다.

\begin{align}
i=j, \quad Cov(X_{i}, X_{i}) = Var(X_{i}) = np_{i}(1-p_{i}) \nonumber
\end{align}

$i=j$일 때는 단순히 $X_{i}$의 **분산**을 구하는 것과 같다. 다항분포를 따르는 확률벡터에 속한 각 확률변수는 **이항분포**를 따르므로 위와 같은 결과를 얻는다.

한편, $i \neq j$일 때는 다항분포의 [덩어리 성질](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_20/#%EB%8D%A9%EC%96%B4%EB%A6%AC-%EC%84%B1%EC%A7%88)에 의해 $(X_{i}+X_{j}) \sim Bin(n, p_{i}+p_{j})$가 성립한다. 따라서 다항분포를 따르는 확률벡터에 속한 두 확률변수 합의 분산은 이항확률변수의 분산 계산법을 그대로 따라 아래와 같다.

\begin{align}
Var(X_{i} + X_{j}) = n(p_{i}+p_{j})(1-p_{i}-p_{j}), \quad i\neq j \nonumber
\end{align}

\begin{align}
Var(X_{i} + X_{j}) - Var(X_{i}) - Var(X_{j}) = 2Cov(X_{i}, X_{j}) \nonumber
\end{align}

\begin{align}
n(p_{i}+p_{j})(1-p_{i}-p_{j}) - np_{i}(1-p_{i}) - np_{j}(1-p_{j}) = -np_{i}p_{j}\nonumber
\end{align}

\begin{align}
\therefore Cov(X_{i}, X_{j}) = -np_{i}p_{j}, \quad i \neq j \nonumber
\end{align}

공분산이 음수로 나타나는 이유는 시행 횟수가 $n$으로 고정된 상태에서 $X_{i}$의 값이 커지면 상대적으로 $X_{j}$의 값은 작아질 수밖에 없기 때문이다.

> 초기하분포

$X \sim Hypo(N, k, n)$일 때 확률변수 $X$의 **기댓값**은 다음과 같이 계산된다. [초기하분포의 PMF](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_08/#2-%EC%B4%88%EA%B8%B0%ED%95%98%EB%B6%84%ED%8F%AC)가 $P(X=k) = \frac{\binom{w}{k}\binom{b}{n-k}}{\binom{b+w}{n}}$임을 이용한다.

\begin{align}
E(X) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= \sum_{k=0}^{n} k \cdot \frac{\binom{w}{k}\binom{b}{n-k}}{\binom{b+w}{n}} \\\\\\ \\\\\\
&= \sum_{k=1}^{n} k \cdot \frac{\binom{w}{k}\binom{b}{n-k}}{\binom{b+w}{n}} \\\\\\ \\\\\\
&= \sum_{k=1}^{n} w \cdot \frac{\binom{w-1}{k-1}\binom{b}{n-k}}{\frac{1}{n} \cdot n \binom{b+w}{n}} \\\\\\ \\\\\\
&= nw \cdot \sum_{k=1}^{n} \frac{\binom{w-1}{k-1}\binom{N-w}{n-k}}{n \binom{N}{n}}
\end{aligned}
\end{equation\*}

우선 $\sum_{k=0}$을 $\sum_{k=1}$로 바꿔준다. 그 다음 [대표 선출하기](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_02/#%EB%8C%80%ED%91%9C-%EC%84%A0%EC%B6%9C%ED%95%98%EA%B8%B0) 예제에서 사용했던 테크닉과 동일한 원리로 $k \cdot \binom{w}{k}$을 $w \cdot \binom{w-1}{k-1}$로 바꿔준다. 그 다음 분모의 $b+w$을 $N$으로 바꾸어 준다. 흰 구슬 개수와 검은 구슬 개수의 합은 전체 구슬 개수와 일치하기 때문이다. 마지막으로 분자의 $b$를 $N-w$로 바꾸어 준다.

\begin{align}
E(X) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= nw \cdot \sum_{k=1}^{n} \frac{\binom{w-1}{k-1}\binom{N-w}{n-k}}{N \cdot \binom{N-1}{n-1}} \\\\\\ \\\\\\
&= \frac{nw}{N} \cdot \sum_{k=1}^{n} \frac{\binom{w-1}{k-1}\binom{N-w}{n-k}}{\binom{N-1}{n-1}} \\\\\\ \\\\\\
&= \frac{nw}{N} \cdot \sum_{i=0}^{n-1} \frac{\binom{w-1}{i} \binom{N-w}{n-i-1}}{\binom{N-1}{n-1}}, \quad i=k-1 \\\\\\ \\\\\\
&= \frac{nw}{N} \cdot \sum_{i=0}^{n-1} \frac{\binom{w-1}{i} \binom{(N-1)-(w-1)}{(n-1)-i}}{\binom{N-1}{n-1}} \\\\\\ \\\\\\
&= \frac{nw}{N}
\end{aligned}
\end{equation\*}

분자를 변환할 때와 같은 테크닉을 이용하여 분모를 변환한다. 그 다음 전체 식을 $i=k-1$로 치환한다. $\sum_{k=1}^{n}$이었으므로 치환하면 $\sum_{i=0}^{n-1}$이 된다. 그렇게 치환을 하고 나면 $\sum$ 이하의 부분이 $Hypo(N-1, i, n-1)$의 PMF임을 확인할 수 있다. 따라서 $\sum$ 이하의 부분은 $1$이 되어 $\frac{nw}{N}$만 남게 된다.

$n$은 시행 횟수이고 $\frac{w}{N}$은 전체 구슬 대비 흰 구슬의 비율이므로 첫 번째 시행의 성공 확률에 해당한다. 따라서 초기하분포를 따르는 확률변수의 기댓값은 **이항확률변수**의 기댓값인 $np$와 매우 유사한 형태임을 알 수 있다.

초기하분포를 따르는 확률변수의 **분산**을 계산하기 위해 먼저 $E(X(X-1))$를 계산한다. $Var(X) = E(X(X-1)) + E(X) - \\\{E(X)\\\}^{2}$이기 때문이다. $E(X(X-1))$의 계산을 위해 **LOTUS**를 활용한다.

\begin{align}
E(X(X-1)) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= \sum_{k=0}^{n} k(k-1) \cdot \frac{\binom{w}{k}\binom{b}{n-k}}{\binom{b+w}{n}} \\\\\\ \\\\\\
&= \frac{nw}{N} \cdot \sum_{k=2}^{n} (k-1) \cdot \frac{\binom{w-1}{k-1}\binom{N-w}{n-k}}{\binom{N-1}{n-1}} \\\\\\ \\\\\\
&= \frac{nw(n-1)(w-1)}{N(N-1)} \cdot \sum_{k=2}^{n} \frac{\binom{w-2}{k-2}\binom{N-w}{n-k}}{\binom{N-2}{n-2}} \\\\\\ \\\\\\
&= \frac{nw(n-1)(w-1)}{N(N-1)} \cdot \sum_{k=2}^{n} \frac{\binom{w-2}{k-2}\binom{N-w}{n-k}}{\binom{N-2}{n-2}} \\\\\\ \\\\\\
&= \frac{nw(n-1)(w-1)}{N(N-1)} \cdot \sum_{i=0}^{n-2} \frac{\binom{w-2}{i}\binom{(N-2)-(w-2)}{(n-2)-i}}{\binom{N-2}{n-2}} \\\\\\ \\\\\\
&= \frac{nw(n-1)(w-1)}{N(N-1)}
\end{aligned}
\end{equation\*}

$E(X(X-1))$을 계산할 때도 $E(X)$을 계산할 때와 같은 테크닉을 $k$에 대하여 한 번, $k-1$에 대하여 한 번 적용하면 결국 $\sum$ 이하의 부분이 $Hypo(N-2, i, n-2)$의 PMF임을 확인할 수 있다. 따라서 $\sum$ 이하의 부분은 $1$이 되어 $\frac{nw(n-1)(w-1)}{N(N-1)}$만 남게 된다.

이제 $Var(X) = E(X(X-1)) + E(X) - \\\{E(X)\\\}^{2}$이므로 대입 후 식을 정리하면 초기하분포를 따르는 확률분포의 분산을 얻어낼 수 있다.

\begin{align}
Var(X) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= \frac{nw(n-1)(w-1)}{N(N-1)} + \frac{nw}{N} - \left(\frac{nw}{N}\right)^{2} \\\\\\ \\\\\\
&= n \cdot \frac{w}{N} \cdot \frac{N-w}{N} \cdot \frac{N-n}{N-1}
\end{aligned}
\end{equation\*}

위 식에서 $n$은 시행 횟수, $\frac{w}{N}$은 전체 구슬 중 흰 구슬의 비율, $\frac{N-w}{N} = \frac{b}{N}$는 전체 구슬 중 검은 구슬의 비율이다. 여기까지는 이항확률변수의 분산인 $np(1-p)$와 매우 유사한 형태이다. 

마지막 항인 $\frac{N-n}{N-1}$은 **유한모집단 수정항**이라 한다. $N-n$이 커질수록 즉, 모집단의 크기 대비 시행 횟수의 차이가 크면 클수록 유한모집단 수정항이 $1$에 가까워져 초기하분포를 따르는 확률변수의 분산은 이항확률변수의 분산에 가까워진다.

또한, $n=1$인 경우에도 이항확률변수의 분산과 같아진다. 왜냐 하면 시행 횟수가 단 한 번인 경우에는 복원추출과 비복원추출에 차이가 없기 때문이다.

초기하분포를 따르는 확률변수의 분산 계산식을 유도하는 다른 방법도 있다. [초기하분포의 기댓값](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_09/#%EC%B4%88%EA%B8%B0%ED%95%98%EB%B6%84%ED%8F%AC)을 계산할 때의 논리를 그대로 적용한다. 즉, $X_{j}$를 각 시행의 성공 여부에 대한 **지시확률변수**로 정의하고 $X = X_{1} + X_{2} + \cdots + X_{n}$로 나타내는 것이다.

\begin{align}
Var(X_{1} + \cdots + X_{n}) = \sum_{i=1}^{n}Var(X_{i}) + 2 \cdot \sum_{i \neq j} Cov(X_{i}, X_{j}) \nonumber
\end{align}

카드 뽑기를 예를 들면 $Var(X_{i})$는 $i$번 카드가 Ace인 사건에 대한 분산에 비유된다. $i$번 카드란 개념에는 **순서**가 포함되지 않으므로 결국 $Var(X_{i})$는 카드 더미에서 카드 한 장을 뽑았을 때 그것이 Ace인 사건에 대한 분산이다. 

이를 수식으로 표현하면 $Var(X_{i}) = p(1-p)$이다. 이러한 분산 항이 $n$개 존재하므로 **분산** 항들의 총합 $\sum_{i=1}^{n}Var(X_{i})$는 $np(1-p)$이다.

한편 $Cov(X_{i}, X_{j}), \;\; i \neq j$는 $E(X_{i}X_{j}) - E(X_{i})E(X_{j})$와 같다. 우선, $E(X_{i})$는 성공 확률 $p$이다. 기댓값의 정의에 의해 $E(X_{i}X_{j}) = 1 \cdot P(X_{i}X_{j} = 1) + 0 \cdot P(X_{i}X_{j} = 0)$이다. 

결국 $E(X_{i}X_{j})$을 계산하기 위해서는 $P(X_{i}X_{j} = 1)$만 알면 된다. $X_{i}X_{j} = 1$이기 위해서는 두 번의 시행이 모두 성공해야 한다. 다시 카드 뽑기를 예를 들면 $i$번 카드와 $j$번 카드가 모두 Ace가 나와야 하는 것이다. 따라서 $P(X_{i}X_{j} = 1)$는 카드 더미에서 카드 두 장을 뽑았을 때 두 장의 카드가 모두 Ace인 확률에 비유된다.

이러한 논리에 따라 $E(X_{i}X_{j}) = \frac{w}{w+b} \cdot \frac{w-1}{w+b-1}$이다. 카드 뽑기의 경우라면 $\frac{4}{52} \cdot \frac{3}{51}$이 될 것이다. $52$장의 카드 중에서 네 장의 Ace 중에 한 장을 뽑고, 처음에 뽑은 한 장의 카드를 제외한 $51$장의 카드 중에서 나머지 세 장의 Ace 중에 한 장을 뽑으면 되기 때문이다.

다시 공분산 계산으로 돌아가면 **공분산** 항은 총 $\frac{n(n-1)}{2}$개 존재하므로 공분산 항의 총합 $\sum_{i\neq j}Cov(X_{i}, X_{j})$는 $2 \cdot \frac{n(n-1)}{2} \cdot \left( \frac{w}{w+b} \cdot \frac{w-1}{w+b-1} - p^{2} \right)$이다.

한 번 더 식을 정리하면 $Cov(X_{i}, X_{j}) = n(n-1) \cdot \left( \frac{w}{w+b} \cdot \frac{w-1}{w+b-1} - p^{2} \right)$가 된다. 이제 분산 항과 공분산 항을 더하면 초기하분포를 따르는 확률변수의 분산 계산식을 얻어낼 수 있다.

\begin{align}
Var(X) = np(1-p) + n(n-1) \cdot \left( \frac{w}{w+b} \cdot \frac{w-1}{w+b-1} - p^{2} \right) = np(1-p) \cdot \frac{N-n}{N-1} \nonumber
\end{align}

$w+b=N$이고 $p=\frac{w}{N}$이므로 대입하여 식을 정리하면 마지막과 같은 깔끔한 결과물을 얻을 수 있다.