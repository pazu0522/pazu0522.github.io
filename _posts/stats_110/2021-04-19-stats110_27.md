---
title:  "확률론 기초(Stats 110) : Lesson 27. Conditional Expectation (2)"
excerpt: "하버드 대학교 조셉 K. 블리츠타인 교수의 Stats 110 27강 정리"

categories:
  - 통계학
  - 확률론
tags:
  - 기댓값
  - 분산
  - 조건부 기댓값
  - 조건부 분산
use_math: true
comments: true
last_modified_at: 2021-04-19T23:30:00
header:
  image: /assets/images/texture.jpg
---

<img src="/assets/images/stats_110/lesson_27.jpg" width="80%" height="80%" title="disease" alt="disease"/> 

# 1. 조건부 기댓값

- [**조건부 기댓값의 성질**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_27/#%EC%A1%B0%EA%B1%B4%EB%B6%80-%EA%B8%B0%EB%8C%93%EA%B0%92%EC%9D%98-%EC%84%B1%EC%A7%88)
- [**조건부 기댓값 예제**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_27/#%EC%A1%B0%EA%B1%B4%EB%B6%80-%EA%B8%B0%EB%8C%93%EA%B0%92-%EC%98%88%EC%A0%9C)
- [**조건부 분산**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_27/#%EC%A1%B0%EA%B1%B4%EB%B6%80-%EB%B6%84%EC%82%B0)
- [**질병 문제**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_27/#%EC%A7%88%EB%B3%91-%EB%AC%B8%EC%A0%9C)
- [**매출액 문제**](https://pazu0522.github.io/%ED%86%B5%EA%B3%84%ED%95%99/%ED%99%95%EB%A5%A0%EB%A1%A0/stats110_27/#%EB%A7%A4%EC%B6%9C%EC%95%A1-%EB%AC%B8%EC%A0%9C)


## 조건부 기댓값의 성질

**조건부 기댓값**은 다음과 같은 몇 가지 성질을 가지고 있다.

- $E(h(X) \cdot Y \mid X) = h(X) \cdot E(Y \mid X)$

확률변수 $X$의 값을 알게 되면 $h(X)$의 값은 자동적으로 알 수 있기 때문에 $h(X)$는 상수가 된다. 따라서 $h(X)$를 기댓값 밖으로 꺼낼 수 있다.

- $X$와 $Y$가 **독립**이면, $E(Y \mid X) = E(Y)$

이 명제의 역은 성립하지 않는다. 따라서, $E(Y \mid X) = E(Y)$가 성립한다고 해서 $X$와 $Y$가 반드시 독립은 아니다.

- $E\Big[E(Y \mid X) \Big\] = E(Y)$

반복 기댓값, **Adam's Law** 또는 전체 기댓값의 법칙 등 다양한 이름으로 불린다. $E(Y \mid X) = g(X)$로 치환하면 $E\Big[E(Y \mid X) \Big\] = E(g(X))$이다. 이제 **LOTUS**와 **전체 확률의 법칙**을 이용하여 성질을 증명한다. 단, 본 증명 과정에서는 $X$와 $Y$가 **이산확률변수**임을 가정하였다.

\begin{align}
E(g(X)) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= \sum_{x}g(x) \cdot P(X=x) \\\\\\ \\\\\\
&= \sum_{x}E(Y \mid X=x) \cdot P(X=x) \\\\\\ \\\\\\
&= \sum_{x} \Bigg( \sum_{y} y \cdot P(Y=y \mid X=x) \Bigg) \cdot P(X=x) \\\\\\ \\\\\\
&= \sum_{y} \sum_{x} y \cdot P(Y=y \mid X=x) \cdot P(X=x) \\\\\\ \\\\\\
&= \sum_{y} \sum_{x} y \cdot P(X=x, Y=y) \\\\\\ \\\\\\
&= \sum_{y} y \sum_{x} P(X=x, Y=y) \\\\\\ \\\\\\
&= \sum_{y} y \cdot P(Y=y) \\\\\\ \\\\\\
&= E(Y) \\\\\\ \\\\\\
&\therefore E\Big[E(Y \mid X) \Big\] = E(Y)
\end{aligned}
\end{equation\*}

- $E\Big[(Y - E(Y \mid X)) \cdot h(X) \Big\] = 0$

위 식에서 $Y - E(Y \mid X)$는 통계학에서 **잔차**를 의미한다. 따라서 잔차와 $X$에 관한 함수는 **비상관**이다. 

좌변을 전개한 후 기댓값의 **선형성**을 이용하면 $E(Y \cdot h(X)) - E\Big\[E(Y \mid X)\cdot h(X)\Big\]$가 된다. 조건부 기댓값의 첫 번째 성질에 의해 $E\Big\[E(Y \mid X)\cdot h(X) \Big\] = E\Big\[E(Y \cdot h(X) \mid X)\Big\]$로 변환 가능하다. 

다시 조건부 기댓값의 세 번째 성질에 의해 $E\Big\[E(Y \cdot h(X) \mid X)\Big\]$는 다시 $E(Y \cdot h(X))$로 변환 가능하다. 따라서 결과값은 $0$이다.

- $Cov \Big\[ Y-E(Y \mid X), h(X) \Big\] = 0$

위 성질의 증명 과정은 다음과 같다.

\begin{align}
Cov \Big\[ Y-E(Y \mid X), h(X) \Big\] \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= E \Big\[ \Big(Y-E(Y \mid X) \Big) \cdot h(X) \Big\] - E \Big \[Y-E(Y \mid X) \Big \] \cdot E(h(X)) \\\\\\ \\\\\\
&= 0 + \Big\[ E(E(Y \mid X)) - E(Y) \Big\] \cdot E(h(X)) \\\\\\ \\\\\\
&= \Big \[ E(Y)-E(Y) \Big \] \cdot E(h(X)) \\\\\\ \\\\\\ 
&\therefore Cov \Big\[ Y-E(Y \mid X), h(X) \Big\] = 0
\end{aligned}
\end{equation\*}


## 조건부 기댓값 예제

> $X \sim N(0, 1)$이고 $Y=X^{2}$일 때, $E(Y \mid X)$와 $E(X \mid Y)$의 값은?

$E(Y \mid X) = E(X^{2} \mid X)$이고 $X$에 대한 정보가 주어졌기 때문에 $X^{2}$의 값을 자동적으로 알 수 있다. 따라서 $E(Y \mid X) = X^{2} = Y$가 성립한다. 한편, $E(X \mid Y) = E(X \mid X^{2})$이다. $X^{2}$에 대한 정보가 주어졌다면 즉, $X^{2} = a$라면 $X$의 값은 $\sqrt{a}$ 또는 $-\sqrt{a}$ 중 하나가 된다는 사실을 알 수 있다. 정규분포의 PDF는 대칭적이기 때문에 $X$가 $\sqrt{a}$ 또는 $-\sqrt{a}$를 값으로 취하게 될 확률은 동일하다. 따라서 기댓값은 $0$이 될 것이다.

> 길이 $1$의 막대를 임의의 지점에서 부러뜨렸을 때 왼쪽 부분의 길이를 $X$라 한다.  
> 왼쪽의 막대를 다시 임의의 지점에서 부러뜨렸을 때 왼쪽 부분의 길이를 $Y$라 한다.  
> 이 때 $Y$의 **기댓값**은?

<img src="/assets/images/stats_110/lesson_27_1.jpg" width="40%" height="40%" title="example1" alt="example1"/>

확률변수 $X$의 정의에 의해 $X \sim Unif(0, 1)$이다. 또한 $X$의 길이가 주어지면 $Y$는 해당 범위 내에서 **균등분포**를 따른다. 따라서 $Y \mid X \sim Unif(0, X)$가 성립한다. 균등분포를 따르는 확률변수의 기댓값은 구간의 중간 지점이므로 $E(Y \mid X=x) = \frac{x}{2}$이다. 따라서 $E(Y \mid X) = \frac{X}{2}$이다. 이제 **Adam's Law**를 이용하여 문제를 해결한다.

\begin{align}
E(Y) = E \Big\[ E(Y \mid X) \Big\] = E \left( \frac{X}{2} \right) = \frac{1}{4} \nonumber
\end{align}


## 조건부 분산

확률변수 $X$와 $Y$에 대한 **조건부 분산** $Var(Y \mid X=x)$는 **분산**과 매우 유사하게 정의된다.

- $Var(Y \mid X) = E \Big\[ (Y-E(Y \mid X))^{2} \mid X \Big\] = E(Y^{2} \mid X) - \Big \[ E(Y \mid X) \Big\]^{2}$

변환 과정은 다음과 같다.

\begin{align}
Var(Y \mid X) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= E \Big\[ (Y-E(Y \mid X))^{2} \mid X \Big\] \\\\\\ \\\\\\
&= E \Big\[ Y^{2} -2Y \cdot E(Y \mid X) + \left \\\{ E(Y \mid X) \right \\\}^{2} \mid X \Big\] \\\\\\ \\\\\\
&= E(Y^{2} \mid X) -2E \Big\[ Y \cdot E(Y \mid X) \mid X \Big \] + E \Big\[ \left \\\{ E(Y \mid X) \right \\\}^{2} \mid X \Big \]
\end{aligned}
\end{equation\*}

$E(Y \mid X)$는 $X$에 대한 함수이므로 $h(X)$로 치환한다. $h(X)$가 함수이므로 $\Big \[h(X) \Big \]^{2}$도 함수이다. 단, $X$가 주어진 상황에서는 $h(X)$와 $\Big \[h(X) \Big \]^{2}$ 모두 **상수**가 되어 기댓값 밖으로 빠져나올 수 있다.

\begin{equation\*}
\begin{aligned}
&= E(Y^{2} \mid X) -2E \Big\[ h(X) \cdot Y \mid X \Big \] + E \Big\[ \left \\\{h(X) \right\\\}^{2} \mid X \Big \] \\\\\\ \\\\\\
&= E(Y^{2} \mid X) -2E (Y \mid X ) \cdot h(X) + \Big\[h(X) \Big\]^{2} \\\\\\ \\\\\\
&= E(Y^{2} \mid X) -2E (Y \mid X) \cdot E(Y \mid X) + E(Y \mid X) \cdot E(Y \mid X) \\\\\\ \\\\\\
&= E(Y^{2} \mid X) - \Big \[ E(Y \mid X) \Big\]^{2}
\end{aligned}
\end{equation\*}

조건부 분산과 관련하여 조건부 기댓값의 **Adam's Law**에 대응되는 **Eve's Law**가 있다.

- $Var(Y) = E \Big\[ Var(Y \mid X) \Big\] + Var \Big\[ E(Y \mid X) \Big\]$

Eve's Law로 불리는 이유는 기댓값-분산-분산-기댓값의 머릿글자를 따면 'EVVE'와 같기 때문이다. 이 법칙의 증명은 다음과 같다. 증명 과정에서 $Var(Y \mid X) = E(Y^{2} \mid X) - \left \\\{ E(Y \mid X) \right \\\}^{2}$이므로 $E(Y^{2}) = E\Big \[ Var(Y \mid X) + \left \\\{ E(Y \mid X) \right \\\}^{2} \Big \]$가 성립한다는 점을 이용한다.

\begin{align}
Var(Y) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= E(Y^{2}) - \Big \[E(Y) \Big \]^{2} \\\\\\ \\\\\\
&= E\Big \[ Var(Y \mid X) + \left \\\{ E(Y \mid X) \right \\\}^{2} \Big \] - E(E(Y \mid X))^{2} \\\\\\ \\\\\\
&= E(Var(Y \mid X)) + \Big \[ \left \\\{ E(Y \mid X) \right \\\}^{2} - E(E(Y \mid X))^{2} \Big \]
\end{aligned}
\end{equation\*}

이제 $E(Y \mid X)$를 $h(X)$로 치환한다.

\begin{equation\*}
\begin{aligned}
&= E(Var (Y \mid X)) + E \Big \[ \left \\\{ h(X) \right \\\}^{2} \Big \] - E \Big \[h(X) \Big \]^{2} \\\\\\ \\\\\\
&= E(Var (Y \mid X)) + Var\Big\[h(X)\Big\] \\\\\\ \\\\\\
&= E \Big\[ Var(Y \mid X) \Big\] + Var \Big\[ E(Y \mid X) \Big\]
\end{aligned}
\end{equation\*}

**Eve's Law**는 **전체 분산**은 **그룹 내 차이**와 **그룹 간 차이**로 구분할 수 있음을 보여준다. 예를 들어 $Y$가 사람들의 키, $X$가 사람들이 속한 그룹을 의미한다면 $Var \Big\[ E(Y \mid X) \Big\]$는 각 그룹에 대한 평균을 확인한 다음 그것의 분산을 계산하는 것이므로 그룹 간 차이를 의미한다. 한편, $E \Big\[ Var(Y \mid X) \Big\]$는 그룹 내의 분산을 확인한 다음 그것의 기댓값을 계산하는 것이므로 그룹 내 차이를 의미한다. 그리고 전체 분산은 그룹 간 차이와 그룹 내 차이의 합으로 표현된다.


## 질병 문제

> 어떤 주(State)에 속한 도시(City)들 중 **무작위**로 한 도시를 선택한다.  
> 선택한 도시의 인구 $n$명을 대상으로 특정 질병의 감염 여부를 확인한다.  
> $X$를 표본에서 해당 질병을 가지고 있는 사람의 수로 정의하고,  
> $Q$를 선택한 도시의 실제 감염률일 때 $X$의 **기댓값**과 **분산**은?  
> 단, 도시를 임의로 선택하므로 $Q$는 확률변수이며 $Q \sim Beta(a, b)$를 가정한다.

도시의 감염률에 대한 정보가 있다면 $X$는 **이항분포**를 따른다고 가정할 수 있다. 따라서 $X \mid Q \sim Bin(n, Q)$이다. 이제 $X$의 기댓값은 다음과 같이 간단하게 계산할 수 있다.

\begin{align}
E(X) = E(E(X \mid Q)) = E(nQ) = n \cdot E(Q) = n \cdot \frac{a}{a+b} \nonumber
\end{align}

$X$의 분산은 **Eve's Law**를 이용하여 계산할 수 있다.

\begin{align}
Var(X) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= E \Big\[ Var(X \mid Q) \Big\] + Var \Big\[ E(X \mid Q) \Big\] \\\\\\ \\\\\\
&= E(nQ(1-Q)) + Var(nQ) \\\\\\ \\\\\\
&= n \cdot E(Q(1-Q)) + n^{2} \cdot Var(Q) \\\\\\ \\\\\\
&= n \cdot E(Q(1-Q)) + n^{2} \cdot \Big \[E(Q^{2})- \\\{E(Q)\\\}^{2} \Big \]
\end{aligned}
\end{equation\*}

이제 $E(Q^{2})$만 계산하면 최종 결과값을 얻을 수 있다.

\begin{align}
E(Q^{2}) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= \frac{\Gamma(a+b)}{\Gamma(a) \cdot \Gamma(b)} \cdot \int_{0}^{1} x^{2} \cdot x^{a-1}(1-x)^{b-1} \; dx \\\\\\ \\\\\\
&= \frac{\Gamma(a+b)}{\Gamma(a) \cdot \Gamma(b)} \cdot \int_{0}^{1} x^{(a+2)-1}(1-x)^{b-1} \; dx \\\\\\ \\\\\\
&= \frac{\Gamma(a+b)}{\Gamma(a) \cdot \Gamma(b)} \cdot \frac{\Gamma(a+2) \cdot \Gamma(b)}{\Gamma(a+b+2)} \cdot \frac{\Gamma(a+b+2)}{\Gamma(a+2) \cdot \Gamma(b)} \int_{0}^{1} x^{(a+2)-1}(1-x)^{b-1} \; dx \\\\\\ \\\\\\
&= \frac{\Gamma(a+b)}{\Gamma(a) \cdot \Gamma(b)} \cdot \frac{\Gamma(a+2) \cdot \Gamma(b)}{\Gamma(a+b+2)} \\\\\\ \\\\\\
&= \frac{a(a+1)}{(a+b)(a+b+1)}
\end{aligned}
\end{equation\*}

$Beta(a+2, b)$의 PDF 형태를 만들기 위해 도중에 적절한 **정규화상수**를 곱하고 다시 나누어준다. 그 다음, **감마함수**의 성질을 이용하여 약분한다.


## 매출액 문제

> 가게에 오는 고객의 수와 각 고객의 지출액이 모두 임의적이라 가정한다.  
> $j$번째 고객의 지출액을 $X_{j}$로, 특정 기간의 고객 수를 $N$으로 정의한다.  
> 각 $X_{j}$와 $N$이 서로 **독립**이며 $E(X_{j}) = \mu$와 $Var(X_{j}) = \sigma^{2}$가 성립한다.  
> 이 때 가게의 총 매출액 $X = \sum X_{j}$의 **기댓값**과 **분산**은?

만약 $X$의 기댓값을 단순하게 $N\mu$로 계산하면 틀린 답이 되는데 그 이유는 $E(X)$는 **상수**인 반면 $N\mu$는 **확률변수**이기 때문이다. 올바른 풀이는 **조건부 기댓값**을 이용하는 것이다.

\begin{align}
E(X) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= \sum_{n=0}^{\infty} E(X \mid N=n) \cdot P(N=n) \\\\\\ \\\\\\
&= \sum_{n=0}^{\infty} n\mu \cdot P(N=n) \\\\\\ \\\\\\
&= \mu \cdot \sum_{n=0}^{\infty} n \cdot P(N=n) \\\\\\ \\\\\\
&= \mu \cdot E(N) \\\\\\ \\\\\\
\end{aligned}
\end{equation\*}

위 과정에서 $N=n$이라는 조건이 주어지는 순간 기댓값의 선형성을 사용할 수 있다. 또한, $N$과 $X$가 **독립**이므로 조건을 없앨 수 있다. 한편, $X$의 기댓값은 **Adam's Law**를 이용하면 더 간단하게 계산할 수 있다.

\begin{align}
E(X) = E(E(X \mid N)) = E(N\mu) = \mu \cdot E(N) \nonumber
\end{align}

$X$의 분산은 **Eve's Law**를 이용한다.

\begin{align}
Var(X) \nonumber
\end{align}

\begin{equation\*}
\begin{aligned}
&= E(Var(X \mid N)) + Var(E(X \mid N)) \\\\\\ \\\\\\
&= E(N\sigma^{2}) + \mu^{2} \cdot Var(N) \\\\\\ \\\\\\
&= \sigma^{2} \cdot E(N) + \mu^{2} \cdot Var(N) \nonumber
\end{aligned}
\end{equation\*}

위 과정에서 $N$과 $X$가 **독립**이므로 **공분산** 항을 고려하지 않아도 된다.
